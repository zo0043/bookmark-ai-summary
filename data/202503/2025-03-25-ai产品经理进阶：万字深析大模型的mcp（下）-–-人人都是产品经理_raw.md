Title: AI产品经理进阶：万字深析大模型的MCP（下） – 人人都是产品经理,

URL Source: https://www.woshipm.com/ai/6190355.html

Published Time: 2025-03-11T19:03:29

Markdown Content:
> 随着人工智能技术的飞速发展，如何让AI系统更高效地与外部数据源和工具进行交互，成为了一个亟待解决的问题。本文将深入探讨一种名为MCP（Model Context Protocol）的新兴技术，供大家学习。

![Image 1](https://image.woshipm.com/2023/04/13/f35c645e-d9dd-11ed-8440-00163e0b5ff3.jpg)

完整大纲：

1、通俗解释MCP

2、MCP的基本概念和定义

3、MCP的起源和发展

4、MCP的核心原理和架构

5、MCP的主要应用场景

6、MCP的优劣及挑战分析

7、MCP的演进方向

让我们继续上一文的内容~

MCP的主要应用场景
----------

MCP作为连接AI与数据/工具的桥梁，最直接的应用场景就是各种**需要将大模型接入外部数据或执行动作的AI应用**。当前，MCP已经在以下几个方面展现出潜力：

### 智能问答和聊天助手

许多企业希望定制自己的大模型助手，让它能访问企业内部知识库、文件文档、客户数据等。MCP非常适合这种场景：开发者可以为不同数据源（Wiki文档、数据库、CRM系统等）各自编写一个MCP服务器，然后让企业版AI助手（如Claude for Work）通过这些服务器获取答案所需的信息。例如，当用户询问“一小时后会议室是否空闲”时，AI助手可以通过调用日历MCP服务器查询会议室预订情况并给出回答。又如客户支持机器人可以通过MCP访问FAQ数据库或工单系统，在对话中实时提取相关答案，而不局限于模型训练内容。这类**知识问答类AI**将因为MCP而具备**实时查证**和**基于私有数据回答**的能力，大幅提升准确性和实用性。Anthropic等公司也提供了Google Drive、Confluence等文档系统的MCP服务器，方便构建智能文档助手，让模型能直接“阅读”最新的文档内容来回答问题。

### 编程辅助与开发者工具

在编程场景下，AI助手往往需要了解用户代码库、依赖文档，甚至执行一些开发相关操作。MCP已经被多家开发工具集成，用于增强AI编程助手的能力。例如，Sourcegraph等代码搜索工具正在利用MCP让AI代理直接检索代码仓库内容，找到相关函数定义或最近的提交记录。开发者可以实现一个Git MCP服务器，提供诸如“查找提交日志”“读取文件内容”等资源/工具，让AI助手在IDE中通过它获取代码上下文。Replit和Zed等IDE厂商也计划通过MCP让AI助手能执行诸如“打开项目Issue列表”“运行单元测试”等操作。这将使AI编程助手从被动回答拓展为**主动协助**：当你在VS Code里调试时，AI可以自己去搜索相关文件、运行测试看看结果，再总结反馈给你。目前Cursor等编辑器已经实现了MCP客户端，支持用户添加自定义MCP工具供其内置的AI Agent使用。可以预见，未来开发工作流的许多环节（构建、部署、代码审核等）都可以通过MCP暴露为工具，交给AI代理完成，从而**自动化**大量重复劳动。

### 办公自动化和个人助理

面向普通用户的AI助手，也有大量与第三方服务集成的需求。借助MCP，可以为常用的**办公应用或云服务**构建连接器，让个人AI助理变得更有用。例如，日程管理AI可以通过一个Calendar MCP服务器读取和修改用户的日历事件；邮件助手AI可以通过Email MCP服务器读取未读邮件并草拟回复；项目管理AI可以通过Jira MCP服务器查询任务状态或新建任务卡片等等。在Claude的桌面应用中，官方已提供Slack聊天、Notion笔记等MCP服务器，用户可以授权Claude助手连接这些服务。这样，当用户对Claude说“请把刚才这份报告发在团队Slack频道”，Claude会自动使用Slack工具执行发送操作。这种**AI驱动的办公自动化**将让个人助理真正成为“数字秘书”，直接操作各种应用完成任务，而不再仅仅是提供建议。

### 分布式系统与DevOps场景

在云计算和分布式系统领域，也出现了使用MCP的可能。一方面，AI可作为**运维助手**接入各类系统监控数据源。比如通过MCP服务器连接到Kubernetes API、AWS云监控等，让AI能够实时获取系统指标、日志信息，并据此分析报告或执行扩容操作。实际上，MCP已有人用于构建简易的**DevOps Agent**：运维人员可以问“现在生产环境CPU使用率如何？”，AI助手即可通过Prometheus MCP服务器查询监控数据并给出答案。如果发现异常，还能调用PagerDuty MCP工具发送告警通知。另一方面，MCP的开放标准也利于**多智能体协作**。在复杂流程中，不同AI Agent可以各自负责一部分任务，通过MCP共享中间数据或工具。例如，一个AI负责规划任务，它可以将子任务下发给不同MCP服务器（其中每个服务器可能挂接一个专用AI Agent）去完成，再汇总结果。这类似于分布式计算中的任务编排，只不过执行者变成AI模型。MCP提供的标准通信协议可以简化这些AI-Agent之间、AI-Agent与系统之间的交互，使构建**分布式AI工作流**成为可能。目前MCP官方路线图中也提到了对**多层级Agent系统**的支持计划

总的来看，MCP的应用场景几乎覆盖**所有需要AI与外界交互的地方**。社区观点认为，MCP的**通用性**使其可以应用于从代码助手、数据分析到个人助理的各种AI应用。一篇分析文章指出：“Unlike previous solutions limited to specific applications, MCP is designed to work across all AI systems and data sources”——也就是说，无论是开发者工具还是数据分析平台，都能用MCP这种统一方式来拓展AI能力。当然，不同行业可能会开发各自领域特定的MCP服务器（比如医疗领域连接医院信息系统的MCP服务器，金融领域连接行情数据的MCP服务器等）。但因为MCP是开放标准，这些连接器一旦开发出来，就可以被任何支持MCP的AI应用复用，从而形成**生态共享**。可以预见，在人工智能迅速渗透各行各业的过程中，一个像MCP这样的统一协议将大大加速AI落地：就好比过去标准化的接口促进了不同系统间的集成，如今MCP正促进AI“大脑”和各种工具“肢体”之间的协作。

MCP的优缺点分析和可能的挑战
---------------

作为一项新兴的开放协议，MCP为AI集成带来了诸多便利和优势，但同时也面临一些局限和挑战。下面我们分别分析其主要**优点**和**缺点/挑战**：

### 主要优点：

*   **标准统一，解决集成碎片化：** MCP最大的价值在于提供了一个**通用标准**，彻底缓解了“每个模型 × 每个工具”都需定制集成的窘境。开发者只需针对MCP编写一次服务器，任何支持MCP的AI客户端都能使用该服务器提供的功能，从而大幅减少开发工作量和维护成本。这种标准化降低了出错概率，也避免了重复造轮子。据VentureBeat报道，过去每接入一个新数据源都要写Python代码或构建LangChain链路，而有了MCP后，这将变成调用标准协议接口。
*   **开源开放，灵活可扩展：** MCP以开放源代码方式发布，并建立了开源社区。这意味着任何人都可以参与改进MCP、开发新插件，实现**社区驱动创新**。相较于封闭的厂商专有接口，开放标准更容易赢得业界支持。MCP已经提供了Python、TypeScript等多语言SDK，方便开发者在自己项目中快速上手。它的设计也充分考虑扩展性，例如支持**自定义传输层**、允许新增原语类型等。这保证了MCP可以随着需求演进，不至于很快过时或无法满足新场景。正如Anthropic所承诺的，将把MCP打造成一个“协作的开源项目和生态”，欢迎各类AI开发者共建未来。
*   **丰富的预构建集成和复用：** 得益于社区力量，MCP已经涌现出许多现成的**连接器实现**。官方提供的多个常用服务MCP服务器只是开始，开发者社区也在贡献更多接入，比如有人实现了Notion文档的MCP服务器、浏览器控制的MCP服务器等等。随着时间推移，会有“现成的MCP插件库”供AI应用直接拿来用。这带来的好处是一种\*\*“即插即用”**的可能：就像浏览器装扩展一样，为AI助手装上新的MCP服务器，它立刻就学会了新本领。另一方面，MCP也允许**能力的重复利用\*\*。企业内部开发的MCP服务器，可以在不同AI产品间通用，不用担心换了模型框架就推倒重来。这种可复用性将大大保护开发投入，并促进一个生态体系的形成。
*   **模型/平台无关，降低厂商锁定：** MCP协议本身与具体的大模型无关，只要AI应用支持MCP客户端，就能接入所有MCP服务器提供的功能。这意味着开发者可以**自由切换LLM或平台**而无需改动后端集成逻辑。例如，今天用Claude接入了几个MCP数据源，明天换成另一个支持MCP的模型（比如开源模型搭建的Agent）也能继续使用这些数据源。这降低了对单一AI厂商的依赖，让企业可以根据效果选择不同模型，同时保持相同的工具接入。不仅如此，MCP也不局限于文本对话模型，未来计算机视觉、语音助手等如果需要上下文数据，同样可以采用MCP标准接入。这种**跨模型、跨平台的通用性**无疑是它的一大卖点。
*   **安全和权限控制内建：** MCP在设计时非常注重**安全性**，为此引入了用户审批、作用域限制等机制。模型调用外部Tool时必须经人类确认，“Sampling”请求也建议有人监督。客户端只会暴露经过配置的本地Roots路径给服务器，防止服务器越权访问敏感数据。此外，传输层采用JSON-RPC也有助于安全审计——所有调用都有迹可循。相比直接给模型接入一堆API没有中间约束，MCP多了一道**安全闸门**，可以显著降低AI系统在开放环境下误用资源的风险。Anthropic也提供了**最佳实践**指南，教开发者如何在基础设施内安全部署MCP服务器，保护数据不泄露。总的来说，MCP努力在**能力与安全**之间取得平衡，让AI既能“做事”，又不会“胡来”。
*   **上下文保持和多步骤流程**： 通过MCP，AI可以**在不同工具之间保持上下文**连续。传统上，如果AI用脚本调用多个API，很难让这些API调用彼此关联。但MCP由于有统一的客户端，可以管理一次对话或任务中的多次调用，使模型调用一系列工具时具备某种事务性和记忆性。例如模型先用一个工具获取了文档ID，再用另一个工具下载该ID文档，MCP客户端可以自动将前一步结果提供给后一步。这在实现复杂Agent时非常关键。再者，MCP的Sampling机制允许嵌入式地再次调用模型，使**多轮推理**成为可能。因此MCP对**复杂工作流**的支持远超简单API调用组合，尤其适合构建那种需要决策-行动反复循环的智能体。

以上优点使很多人认为MCP将**极大提升AI系统集成效率和能力**。然而MCP也并非万能，在当前阶段还有一些明显的限制和挑战需要克服：

### 主要缺点和挑战：

*   **生态体系尚处起步，支持度有限：** 作为2024年底才推出的新协议，MCP目前的生态圈还比较小。尽管Anthropic率先在Claude中支持了MCP，并推动了一些合作伙伴采用，但其他主流AI模型（如OpenAI的ChatGPT、Google的Bard等）尚未直接支持MCP。这意味着**互操作性**还未真正实现：开发一个MCP服务器，目前主要服务于Claude用户群。如果目标用户使用的是不同AI助手，MCP的价值就难以发挥。这需要时间来培养生态，需要行业主要玩家的认可。存在的风险是**标准之争**：如果其它大厂不加入MCP阵营，可能各自推出类似但不兼容的方案，反而造成新的碎片化。这就要求Anthropic在标准推进上积极与各方合作，也可能需要引入独立的标准组织来主导（MCP路线图中提到了考虑通过标准化机构来推动）。总之，**网络效应**对MCP非常重要。目前MCP还**称不上成熟的行业标准**，更像是一个有前景的候选，需要社区和产业进一步响应。
*   **目前功能局限（特别是远程支持）：** 现阶段MCP主要支持本地部署的AI助手与本地运行的服务器通信（通过stdio管道）。对于远程MCP服务器的支持还在开发中，例如需要完善**身份认证、权限授权**等机制，以便安全地通过网络访问MCP服务。根据官方路线图，他们将引入OAuth 2.0等认证方式，以及服务发现、无状态操作等功能。在这些完成前，大多数使用场景仍限定在同一台机器或受控环境内。这在一定程度上**限制了MCP的用武之地**，因为许多企业数据源在内网或云端。如果无法方便地远程连接，MCP的实用性会打折扣。不过好消息是官方已将“Remote MCP”作为首要优先事项，相信不久就会支持服务器端部署和云端调用。在那之前，用户可能需要自行通过SSH隧道、反向代理等方式绕过，这对一般开发者来说增加了复杂度。
*   **学习成本和心智负担：** 对开发者而言，MCP引入了一些全新的概念（如Prompts/Tools/Resources分类、客户端/服务器双端开发等）。要采用MCP，需要理解协议规范、掌握SDK使用方式，这相比直接写脚本调用REST API显得更重一些。在初期阶段，文档完善度和社区支持也有限，一些开发者可能觉得MCP“门槛”较高或踩坑机率大。此外，从运维角度看，引入MCP意味着要运行额外的服务器进程、管理这些进程的生命周期和版本升级，这也增加了系统复杂性。尤其当数据源本身已经有成熟API时，再封装一层MCP似乎显得多余。这就需要一个**理念转变**：把MCP视为架构的一部分而非简单工具，否则对其价值认知不到位就很难投入成本去采用。因此，MCP在推广上需要降低开发者的心理阻力——通过提供丰富的模版、简单的上手例子、完善的调试工具（好在官方已提供“MCP Inspector”这类调试工具）来减少学习曲线。
*   **性能与效率考量：** 虽然对于大多数交互场景，MCP的JSON-RPC通信开销不算瓶颈，但在极端高性能要求下，它可能不如某些定制集成高效。比如，每次模型调用工具都要JSON序列化、用户审批、再序列化，**延迟**会比模型直接调用内部函数高。另外，如果有大量并发调用，MCP服务器可能成为瓶颈，需要做好横向扩展。而目前的SDK和参考实现是否足够高效，有待大量生产环境验证。相比之下，直接使用二进制RPC（如gRPC）或内嵌插件可能在**吞吐量**上更有优势。因此MCP更适合一次调用链不长、对实时性要求不苛的任务。如果要用MCP做高频实时数据推送（例如每秒成百上千次事件通知模型），可能需要调优或等待协议的性能改进。同时，MCP作为中介层，也引入了新的**故障点**：如果MCP服务器挂掉或卡死，模型就失去那个数据源。所以在关键任务场景，需要对MCP服务器进行监控和容错设计，这增加了系统复杂度。
*   **安全与滥用防范：** 虽然MCP有用户审批等机制，但安全仍然是很大挑战。首先，用户审批在提升安全的同时也降低了体验——如果模型频繁请求调用工具，用户不断点击允许会烦不胜烦，甚至可能一时大意批准了不应批准的操作。这就需要在**便利和安全**间找到平衡，例如对低风险操作自动批准，高风险操作严格把关。其次，MCP打开了模型与外界互联的大门，也就增加了被恶意利用的可能。比如，假如模型被提示攻击，引诱用户批准执行某不良工具，那后果可能很严重。这需要在产品层面对**社工防范**、**权限分级**做更多设计。对于在企业环境中运行的MCP服务器，还得考虑**访问控制**：哪些用户或模型可以调用哪些工具，需要细粒度权限，否则一旦某个模型凭借MCP获得了全公司数据访问权，那风险极大。目前MCP刚推出，对于这些深层次安全问题仍在探索阶段。解决这些问题可能需要引入**更强的身份验证、权限管理体系**，甚至借鉴零信任架构来限定每次调用的范围。
*   **标准推进和竞争：** 最后从产业角度，MCP也面临**标准存亡**的挑战。历史上，很多技术标准并非技术最优就能胜出，还取决于大厂支持和市场接受度。MCP目前由Anthropic主导，这既是优势（有知名AI企业背书），也是风险（其他竞争者可能不愿采用“别人的标准”）。OpenAI、Google也在让自家模型通过插件或工具扩展，如果他们选择各搞各的标准，开发者就会观望甚至放弃MCP。这对MCP推广很不利。不过Anthropic显然意识到了这一点，在努力**推动社区共治**。他们在路线图中提到要“通过平等参与和共享治理来促进所有AI提供商共同塑造MCP”。也就是说，希望未来成立一个中立的联盟或标准组织，使MCP真正成为大家的协议，而非一家之言。这需要各方有共识：继续各自为政大家都麻烦，不如携手定标准共赢。目前来看，至少一些中小型AI企业和开源社区对MCP是持欢迎态度的，但需要更广泛的联盟。当然，也存在MCP被替代的可能——万一出现另一套更简单或更强大的协议且得到广泛支持，MCP可能被边缘化。因此Anthropic和社区需要不断改进MCP，使其保持技术先进性和易用性，以应对潜在竞争。这是一场**技术和时间**的赛跑。

总体而言，**MCP利大于弊**。它抓住了AI落地过程中的痛点并提供了一个优雅解决方案，其标准化带来的长远收益（生态繁荣、效率提升）很可观。但它当前的不足也不容忽视，需要在技术完善、生态拓展、安全保障等方面持续努力。正如一些论坛网友所言，MCP要成功，不仅要有好的技术设计，更需要经营一个**繁荣的社区**和**被广泛接受的行业规范**。这既是机遇也是挑战。

MCP的未来潜力和演进方向
-------------

尽管MCP还处于早期阶段，但其展现出的潜力让人对其未来充满期待。随着AI技术的发展和行业协作的加强，MCP可能在以下几个方向上演进：

### 更成熟的远程和云支持

未来MCP最重要的里程碑之一就是**完全支持远程服务器**。根据路线图，官方正在开发统一的认证授权机制（如OAuth2）、服务发现、无状态操作支持等，以便客户端能够方便安全地连接分布在云端的MCP服务器。这将打开**云端AI集成**的大门：企业可以在自己的服务器或云上部署MCP服务器，将私有数据开放给云端AI模型使用，同时确保访问受控安全。一旦这项能力成熟，MCP将不再局限于本地桌面应用，而可以适用于**SaaS AI服务、云代理**等更多场景。同时，为支持大规模的云部署，MCP或将引入**无状态模式**以便水平扩展。比如让多个无状态MCP实例在负载均衡后面共同服务，以承载高并发请求。这些改进都会使MCP更加企业级和可扩展。

### 标准化分发与“应用商店”

设想当有成百上千个MCP服务器可用时，如何让用户方便地获取并安装所需的服务器？未来MCP生态可能出现**标准的打包和分发机制**。例如类似Docker镜像或VS Code扩展的仓库，集中托管各种MCP服务器实现，用户通过一个命令就能下载并运行所需的服务器。这涉及**打包格式**标准化、**安装工具**开发以及**服务器注册中心**建设。一旦实现，MCP的推广将更为迅猛——开发者分享一个MCP插件，用户能像装App一样一键启用。这有点像打造AI助手的“**应用商店**”，只不过这些“App”是各种数据源/工具连接器。例如，一个安全分析MCP服务器打包后上传社区，所有需要此功能的AI助手都可轻松集成。这种**集中发现与分发**机制将极大降低MCP功能获取的门槛，推动其生态繁荣。

### 复杂Agent和多智能体支持

AI代理的发展是当前AI领域的热门方向之一。MCP天然适合作为**多Agent协作**的通信层，未来版本也计划增强这方面能力。例如，引入**层次化Agent系统**支持，通过命名空间或拓扑结构让一个Agent可以管理下属子Agent。这可能意味着MCP可以在一个主机内注册多个不同级别的客户端，每个负责一类任务。另外，针对多Agent互相请求用户许可、信息共享的问题，MCP可能设计更好的**权限传递和用户交互**方案。例如，当一个子Agent需要用户许可时，可以通过父Agent统一请求，以免用户被大量分散的请求淹没。还有在长时间运行操作时提供**实时进度更新**（Streaming Results）等，也是在Agent场景下很有用的功能。这些改进将使MCP成为构建**自主AI系统**的有力工具，让复杂任务分解、并行处理、结果汇总都通过标准协议完成。**扩展至多模态与新领域：** 目前MCP主要围绕文本交互和传统数据源设计，但未来很可能拓展到**多模态AI**领域。例如，为了支持图像生成模型，MCP服务器可以提供图像资源（如读取一张图片）或图像工具（如调用OCR识别）。再比如语音助手，可以有音频输入输出的Resource类型，或硬件设备控制的Tool类型。路线图提到将考虑**音频、视频等格式**的支持。这可能需要对协议做一些增强，比如支持二进制数据传输（目前JSON-RPC不太适合大二进制blob）。但这些都是可解决的问题。此外，随着AI模型能力拓展，MCP也可能增添新的原语类型。例如也许未来引入“**交互式会话**”原语，允许服务器与模型持续对话，或“**知识库**”原语，允许模型查询大规模嵌入式向量数据库等。这些都取决于实际需求和社区提案。开放的结构意味着MCP能够适应AI技术演进，不局限于当前定义。

### 治理和标准化

如前所述，MCP要长远发展，必须走向**行业标准化**道路。可以预见，Anthropic不会一直单方面决定MCP规范细节，而是会寻求一个更开放的治理模式。可能的路径包括成立**MCP工作组**，吸收各大AI公司、开源社区代表共同参与标准制定；或者把MCP提案提交给像IEEE、W3C这类标准组织审核通过。一旦上升为行业标准，厂商采用MCP的意愿会更强，也有助于在敏感问题上达成一致（比如安全规范、版权责任划分等）。不过标准化的过程需要各方让步和协商，也意味着MCP规范的发展会更稳健而不是Anthropic一家公司说了算。这对MCP的**长期生命力**是好事。可以想象一个场景：五年后，大部分新的AI应用开发时都会**默认支持MCP接口**，就像今天的浏览器默认支持HTML/JS一样自然。而MCP标准本身可能也经历多个版本迭代，吸收实践经验变得更加完善。

### AI助理新范式的催化剂

从更远的角度看，MCP的成熟有望催生一些**新颖的AI应用范式**。例如，个人层面可能出现\*\*“AI数字助手网络”**：用户的手机、电脑上跑着各种MCP服务器（访问传感器、日历、邮件等），个人的AI代理可以随时接入完成任务。不同用户的AI助手之间甚至可以通过各自MCP接口协作（当然基于用户授权），形成一种**群体智能\*\*。在企业层面，如果大家都采用MCP，一家公司内部不同部门的AI工具也能通过标准接口交互，实现跨部门的AI流程自动化。再比如，AI应用商店、AI技能交换市场等概念都更加容易实现——因为标准接口降低了兼容成本。可以说，MCP有潜力成为**AI时代的基础协议**之一，把如今相对孤立的AI功能串联成更大规模的智能网络。这种前景是令人兴奋的。

总的来说，MCP目前只是迈出了“万里长征第一步”。但其背后的思想——为AI与环境交互建立统一接口——注定会在未来持续发展。正如Marc Nuri在博客中总结的：“MCP是一个革命性的标准，有望改变AI应用与世界交互的方式…随着AI代理的发展，MCP将在让它们理解和响应周围世界方面发挥关键作用”。当然，这个过程中还有许多技术和非技术问题要解决，但MCP已经点燃了业界对**“AI上下文接口”**的想象。不夸张地说，如果MCP或类似标准成功落地，我们将迎来一个AI系统高度互联的时代——人工智能将不再是一个个孤岛，而会通过标准接口融入我们的数字生态，就像电器插上了通用电源插座一样，开始发挥更大价值。

MCP的核心价值就在于**统一标准、消除隔阂**。它把AI和外界连接的方式从“烟囱林立”变成了“道路纵横”，让信息和指令能够自由流通。当然，比喻终归是比喻，真正实现起来MCP还有许多技术细节和挑战。但如果抓住大方向，我们可以期待MCP引领AI生态从各自为政走向开放联通，就像互联网协议统一了网络通信一样。总而言之，MCP给AI装上了一个标准接口插头，未来无论想连什么，**插上就可以用**。这将帮助我们构建出更加强大、灵活的AI应用，迎接一个万物智联的时代。

本文由 @AI贾维斯 原创发布于人人都是产品经理。未经作者许可，禁止转载

题图来自Unsplash，基于CC0协议

该文观点仅代表作者本人，人人都是产品经理平台仅提供信息存储空间服务
