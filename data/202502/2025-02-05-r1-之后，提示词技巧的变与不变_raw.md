Title: R1 之后，提示词技巧的变与不变

URL Source: https://mp.weixin.qq.com/s/-51tjTWRdi19sEBCQMe1sw

Markdown Content:
我在一周前的文章\[1\]里说对 DeepSeek-R1 只需要说大白话，但在三天前的文章\[2\]里又用了看起来还挺复杂的结构化提示词。有伙伴问我到底咋回事。这就来解释下喽。

### 1\. 你依旧需要告诉 AI 足够多的背景信息

我一直都很推崇大白话式的提示词。

最近多次看到群友发出对比：“图一是使用大白话的结果，图二是用上 XX 提示词技巧的结果，后者效果好得多！提示词技巧还是需要的！”

但效果差真的是大白话的锅吗？还是因为你的大白话提供的信息太少？

大模型是人类智慧的加权平均，不断用概率来预测下一个 token。许愿式的“给我写段 XXX”，得到的只能是符合人类偏好平均值的（因而也是最平庸的）结果。

我们来看一个特别简单的例子。

“蛇年拜年短信”。当你听到这个词时脑袋里最先出现的是什么词？灵蛇、金鳞、喜、乐、福、财……对不对？

巧了，大模型也是这么想的！

因此，许愿式的一句简单指令，大概率会得到这样的结果：

![Image 21](https://mmbiz.qpic.cn/sz_mmbiz_png/sLRSg8JfIeaOPm4TThUnr6kibBKVSmauicddoRt51kyk5zjufIC97rMzhibFiba8JvwE11w2YoGCIZC7NPCvv8lPIA/640?wx_fmt=png&from=appmsg)

但若用大白话把你是谁、要写给谁、写什么说清楚，就完全不同了：

![Image 22](https://mmbiz.qpic.cn/sz_mmbiz_png/sLRSg8JfIeaOPm4TThUnr6kibBKVSmauicfMrqmDsarYf6e3FnyNPOSsl9ojudwHcoofPbWenewRsIOUhh9icgDPA/640?wx_fmt=png&from=appmsg)

所以，不是大白话不行，而是信息量太少的大白话不行。你依旧需要告诉 AI 足够多的背景信息，让大模型知道你的偏好。

### 2\. 提示词框架依旧有效，是因为它能提醒你提供必要信息

两年前大家研究提示词工程，提出了五花八门的框架。照框架写出来的提示词，似乎比大白话“高级”了一些。

其实，这些框架大同小异、万变不离其宗，只是你思考的脚手架而已。对照着框架，你或许会想起还遗漏了哪些背景信息，应该要告诉大模型。

面对 R1，你依旧需要对大模型提供必要的背景信息，因此这些辅助梳理信息的框架依旧有用。但你完全可以有自己的判断——遗漏的条目就补上，不适用的就删了，不需要拘泥于框架。（其实 R1 之前也是这样）

![Image 23](https://mmbiz.qpic.cn/sz_mmbiz_png/sLRSg8JfIeaOPm4TThUnr6kibBKVSmauicbOrExdzFTsT1DnKdibdIf0kZdsKOTQia7mfNxwsxdA2ursuia21FL1anA/640?wx_fmt=png&from=appmsg)

### 3\. 用乔哈里视窗分析你到底该告诉 AI 多少信息

到底哪些信息需要告诉 AI、哪些不需要呢？李继刚有个特别棒的分享\[3\]，介绍用乔哈里视窗来分析不同情况下、分别要如何写提示词。如果对下图有疑惑，推荐阅读原文。

![Image 24](https://mmbiz.qpic.cn/sz_mmbiz_png/sLRSg8JfIeaOPm4TThUnr6kibBKVSmauicZ0OhUjyyLe5jxNMjZNmB3ictUarLQKLe7UUmJB9uR9Hq7fskycrZSKg/640?wx_fmt=png&from=appmsg)

### 4\. 结构化提示词有助于 AI “记住”和遵循指令

在 ChatGPT 时代，很多人都喜欢结构化提示词，像 coze 等平台还会自动把你的大白话提示词优化成结构化形式。# 或 ## 的符号一加，看上去就特专业。

![Image 25](https://mmbiz.qpic.cn/sz_mmbiz_png/sLRSg8JfIeaOPm4TThUnr6kibBKVSmauicgbA15GePbePLXTSCBib3ric7QIHgKQ3ZMZiaXzNFgUtGNMiaLwxPDiaIRZg/640?wx_fmt=png&from=appmsg)

有必要这么做吗？其实得看你的提示词有多复杂——复杂内容用结构化方式梳理，效果确实会提升。原因我在拆解 Mr. Randeer 时有解释。\[4\]

人类用思维导图可以很好地帮助记忆，因为它将线性的内容分门别类组织成树状结构，内容被分块且呈现关联，记忆负担就小了。

大模型也有类似的现象。用特殊符号把大段提示词分块（#，## 之类的符号是 Markdown 语法中的一级标题、二级标题等），就像是把提示词画成张思维导图，AI 会更容易“记住”和遵循这些指令。

除了 Markdown 格式，用 <类xml 标签\> 或者 @@@@以下是公司简介@@@@ 这样随性的分割线，只要能把内容清晰分块，效果也都不赖。

这个技巧，对 R1 模型依旧有效。但如果提示词不复杂，其实不用那么费劲。

### 5\. 不要在提示词里指定思考步骤，除非你只希望 AI 严格执行

这一条是 R1 和以前模型最大的区别。

以前在提示词里用 CoT（Chain of Thoughts，思维链）的方式把中间过程都写出来，能有效提升大模型表现。但对 R1 这么做很可能起反作用。原因很简单：R1 的深度思考往往能比你想得更多。

例如前面的拜年短信，基本上我想到的、没想到的，它都帮我想到了。也就是说，“如何做”的信息，落在了乔哈里视窗“AI 知道”这半区，那我们只需要把目的说清楚即可。

![Image 26](https://mmbiz.qpic.cn/sz_mmbiz_png/sLRSg8JfIeaOPm4TThUnr6kibBKVSmauicq50fvjOnDibPfhEr3L31EJicSSXqkfG5IZBf51gTJ6vYV0uSsyKoeHicg/640?wx_fmt=png&from=appmsg)

当然，如果你有特定的方法论，就是希望 AI 严格按你说的做，那用 CoT 也可以。但我强烈建议你在添加 CoT 之前，和 R1 自由对话几轮，参考它的思考过程，来改进你的步骤。

毕竟，一个不太能干的领导，用太过微管理的方式来指挥员工干活，是非常扼杀聪明员工的灵气的。

### 6\. 示例是另一种背景信息，可以按需提供

以前的提示词技巧中，还经常会讲到要“给示例”。这是 In-Context-Learning, one-shot，few-shots，都能明显提升大模型的表现。

示例是一种隐性的需求说明书——当你描述的要求太抽象/不够准确时，添加一两个示例，可以让大模型更懂你需要的是什么（就让人类在领任务的时候说“你能不能举个例子”）。这技巧对 R1 也依旧有效。

为了避免 overfitting，你的例子最好别太单一。否则大模型会刻板以为你要的就这一种，依葫芦画瓢出来的结果也单调。

和上一条类似，你可以先和 R1 自由对话几轮，从它生成的内容里挑好的例子放入提示词。

比较特别的是：既然目的是提供更多偏好信息，你还可以用非常简单的大白话来给例子，R1 有能力举一反三、捕捉关键点、并加以扩充。

例如下图提示词里高亮的其实也是示例：

![Image 27](https://mmbiz.qpic.cn/sz_mmbiz_png/sLRSg8JfIeaOPm4TThUnr6kibBKVSmauicoOnY2pCOKq8gebIhibdfDqfxDEFBicWGdNmQ6xsatCGeopNhCq4Uyt4w/640?wx_fmt=png&from=appmsg)

R1 会捕捉住“用图像生成能力增加趣味”的关键点，并主动生成完整内容。

![Image 28](https://mmbiz.qpic.cn/sz_mmbiz_png/sLRSg8JfIeaOPm4TThUnr6kibBKVSmauicJfvW3yMl0d207EOKyhu1ctU2c0mWEzO3GLOBE2SvcWPYic6kVIEI9SA/640?wx_fmt=png&from=appmsg)

### 7\. 提示词要区分自用还是他用、一次性还是反复用

如果是自己的非重复任务，你不需要使用上两条提示词技巧：只要在对话过程中提出新要求就好，在追问中补充信息，比一开始就思考周全，要容易地多。

只有需要反复使用的任务，才值得你仔细打磨带有步骤或示例的、有框架和结构、能有稳定表现的高质量提示词。

其实这样的提示词也可以用一个 meta-bot 自动生成并优化，GPTs 时代已经有很多了，R1 会有一些不同，以后另写文章介绍。

### 8\. R1 的指令遵循差，可用分工协作来改进

说起稳定表现，相比以前的指令型大模型，R1 “有脑子”、“会思考”了，就像更聪明的员工那样，可能会不太听话。

它对指令的遵循比以前的模型要更难些。我们可以通过看它的思考过程来理解原因，进而调整提示词、强调重要内容。

但其实我们也不需要死磕，让模型分工协作可能是更好的办法。先让 R1 （慢思考的系统 2）自由生成内容，再用其它指令遵循较好的小模型（快思考的系统 1）对它的输出进行一番整理就好。

在一条提示词里塞了很多任务，也会让大模型更不听话。一口气交代员工做十件事、肯定比一件一件让它做，要更难呀。把任务拆分了、用工作流框架串起来，会是更好的做法。

### 9\. 有用的不是提示词技巧，而是你的思考和表达

我在旧文“一个一串一串串——比提问更重要的是追问“\[5\]里写过，提示词技巧保证的是 AI 回复质量的下限，但提升上限，要靠提示词中的具体内容。

R1 对框架、结构、CoT、ICL 等的要求更少、因此保障下限更容易，对发挥大模型能力影响更大的，就是我们自身的思考和表达了。

使用 AI 真的很简单，再小白，也不需要去上提示词课。  
但可能每个人，都需要补语文课、逻辑课、批判性思维课。

* * *

我是在技术和教育圈来回串的贪玩的好奇星人。欢迎点赞点收藏关注加星，近期我的 DeepSeek 话题列表已经堆积了十来个话题，会勤快更新的。也期待多多评论区交流。

拓展阅读：

\[1\]:[当你惊呼 DeepSeek 成精时，请警惕前方的陷阱](https://mp.weixin.qq.com/s?__biz=MzA4MjM5MDI0Ng==&mid=2648507876&idx=1&sn=67a3a52cb8b4c0094d464dee995c8c72&scene=21#wechat_redirect)  
\[2\]:[DeepSeek：好奇宝宝的免费一对一科学老师](https://mp.weixin.qq.com/s?__biz=MzA4MjM5MDI0Ng==&mid=2648508050&idx=1&sn=748633f3e5d22f9c20f5817048c05714&scene=21#wechat_redirect)  
\[3\]:[李继刚 | 提示词的道与术](https://mp.weixin.qq.com/s?__biz=MzkzNzY2MDEyNA==&mid=2247484401&idx=2&sn=9b4eb57d4b6315e522e6f407d2d23f0f&scene=21#wechat_redirect)  
\[4\]:[深度拆解天花板级复杂的提示词 ——什么可照搬什么不要学](https://mp.weixin.qq.com/s?__biz=MzA4MjM5MDI0Ng==&mid=2648505470&idx=1&sn=fa7a7e662255990f8bf80db0d1cec7b0&scene=21#wechat_redirect)  
\[5\]:[一个一串一串串——比提问更重要的是追问](https://mp.weixin.qq.com/s?__biz=MzA4MjM5MDI0Ng==&mid=2648505579&idx=1&sn=26d440ec90a25ec8c33b7588dd2714ef&scene=21#wechat_redirect)
