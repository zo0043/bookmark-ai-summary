# How to Make LLMs Shut Up
- URL: https://www.greptile.com/blog/make-llms-shut-up
- Added At: 2025-01-02 02:40:42
- [Link To Text](2025-01-02-how-to-make-llms-shut-up_raw.md)

## TL;DR
Daksh Gupta在Greptile博客分享了减少LLM代码审查评论数量的方法，通过聚类和向量数据库过滤低质量评论，提高评论解决率。

## Summary
1. **文章背景**：
   - 作者：Daksh Gupta，Greptile联合创始人
   - 主题：如何减少大型语言模型（LLM）在代码审查中产生的评论数量和质量
   - 时间：2024年12月18日
   - 来源：Greptile博客

2. **问题起源**：
   - Greptile的AI代码审查工具最初被用户投诉评论过多，导致开发者忽视。
   - 需要减少评论数量，并评估评论质量。

3. **解决方案探索**：
   - **方法一**：利用GitHub的点赞/踩赞功能作为质量指标。
   - **方法二**：检查作者在后续提交中是否解决了评论。
   - **方法三**：使用LLM作为评判者，评估评论+diff对的重要性。

4. **尝试与失败**：
   - **尝试一**：通过提示工程减少评论数量，但未能成功。
   - **尝试二**：使用LLM作为评判者，但LLM的判断结果随机，效率低下。

5. **转向学习**：
   - 识别到“nits”（无关紧要的评论）是主观的，不同团队的标准不同。
   - 考虑微调LLM，但成本、速度和可移植性限制了这一方案。

6. **最终方案：聚类**：
   - 为每个团队生成评论的嵌入向量，并存储在向量数据库中。
   - 通过与已下架的评论进行相似度比较，过滤掉低质量的评论。

7. **结果**：
   - 该方法有效减少了LLM产生的噪音。
   - 在推出该功能两周后，用户解决的评论比例从19%增加到55%以上。

8. **未来展望**：
   - 这是一个持续的问题，作者计划在看到更多进展时撰写后续文章。
