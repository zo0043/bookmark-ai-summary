#!/usr/bin/env python3
"""
ç‹¬ç«‹æµ‹è¯•è„šæœ¬ï¼šéªŒè¯æ”¹è¿›çš„ slugify å‡½æ•°ï¼ˆä¸ä¾èµ–å¤–éƒ¨æ¨¡å—ï¼‰
"""

import hashlib
import re

# é…ç½®å¸¸é‡ï¼ˆä»åŸæ¨¡å—å¤åˆ¶ï¼‰
MAX_FILENAME_LENGTH = 80
HASH_LENGTH = 8
TRUNCATE_PREFIX_LENGTH = 50
TRUNCATE_SUFFIX_LENGTH = 20
SEPARATOR = "..."

# é…ç½®éªŒè¯
if not (20 <= MAX_FILENAME_LENGTH <= 255):
    raise ValueError(f"MAX_FILENAME_LENGTH ({MAX_FILENAME_LENGTH}) å¿…é¡»åœ¨ 20-255 ä¹‹é—´")
if not (4 <= HASH_LENGTH <= 32):
    raise ValueError(f"HASH_LENGTH ({HASH_LENGTH}) å¿…é¡»åœ¨ 4-32 ä¹‹é—´")
if TRUNCATE_PREFIX_LENGTH + TRUNCATE_SUFFIX_LENGTH >= MAX_FILENAME_LENGTH - len(SEPARATOR) - HASH_LENGTH:
    import warnings
    warnings.warn("æˆªæ–­é•¿åº¦é…ç½®è¾ƒå¤§ï¼Œå»ºè®®è°ƒæ•´ä»¥ç¡®ä¿è¶³å¤Ÿçš„æ–‡ä»¶åç©ºé—´", UserWarning)

# æ€§èƒ½ä¼˜åŒ–ï¼šé¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
_INVALID_FS_CHARS_PATTERN = re.compile(r"[/" + re.escape('/\\:*?"<>|') + r"\s]+")
_COMPILED_HASH_CACHE = {}  # ç®€å•çš„LRUç¼“å­˜

def slugify(text: str) -> str:
    """å°†æ–‡æœ¬è½¬æ¢ä¸ºé€‚ç”¨äºæ–‡ä»¶åæˆ–URLçš„"slug"æ ¼å¼ï¼Œæ”¯æŒé•¿åº¦é™åˆ¶å’Œæ™ºèƒ½æˆªæ–­"""
    if not text:
        return ""

    # åŸºç¡€æ¸…ç†ï¼šä½¿ç”¨é¢„ç¼–è¯‘çš„æ­£åˆ™è¡¨è¾¾å¼æé«˜æ€§èƒ½
    cleaned = _INVALID_FS_CHARS_PATTERN.sub("-", text.lower()).strip("-")

    # å¦‚æœé•¿åº¦åœ¨é™åˆ¶å†…ï¼Œç›´æ¥è¿”å›
    if len(cleaned) <= MAX_FILENAME_LENGTH:
        return cleaned

    # ä½¿ç”¨ç¼“å­˜æé«˜æ€§èƒ½ï¼ˆé€‚ç”¨äºé‡å¤çš„è¾“å…¥ï¼‰
    cache_key = (text, MAX_FILENAME_LENGTH, HASH_LENGTH, TRUNCATE_PREFIX_LENGTH, TRUNCATE_SUFFIX_LENGTH)
    if cache_key in _COMPILED_HASH_CACHE:
        return _COMPILED_HASH_CACHE[cache_key]

    # ç”ŸæˆåŸæ–‡æœ¬çš„å“ˆå¸Œå€¼ç¡®ä¿å”¯ä¸€æ€§
    hash_suffix = hashlib.md5(text.encode('utf-8')).hexdigest()[:HASH_LENGTH]

    # è®¡ç®—å¯ç”¨é•¿åº¦ï¼ˆå‡å»åˆ†éš”ç¬¦å’Œå“ˆå¸Œï¼‰
    available_length = MAX_FILENAME_LENGTH - len(SEPARATOR) - HASH_LENGTH

    # æ™ºèƒ½æˆªæ–­ï¼šä¿ç•™å‰ç¼€å’Œåç¼€
    prefix_length = min(TRUNCATE_PREFIX_LENGTH, available_length // 2)
    suffix_length = min(TRUNCATE_SUFFIX_LENGTH, available_length - prefix_length)

    # æ„å»ºæˆªæ–­åçš„æ–‡ä»¶å
    prefix = cleaned[:prefix_length]
    suffix = cleaned[-suffix_length:] if suffix_length > 0 else ""

    truncated_name = f"{prefix}{SEPARATOR}{suffix}_{hash_suffix}"

    # ç¡®ä¿æœ€ç»ˆé•¿åº¦ä¸è¶…è¿‡é™åˆ¶
    if len(truncated_name) > MAX_FILENAME_LENGTH:
        # å¦‚æœä»ç„¶è¿‡é•¿ï¼Œè¿›ä¸€æ­¥ç¼©çŸ­å‰ç¼€
        excess = len(truncated_name) - MAX_FILENAME_LENGTH
        prefix = prefix[:-excess]
        truncated_name = f"{prefix}{SEPARATOR}{suffix}_{hash_suffix}"

    # ç¼“å­˜ç»“æœï¼ˆç®€å•çš„FIFOç¼“å­˜ï¼Œé™åˆ¶å¤§å°ï¼‰
    if len(_COMPILED_HASH_CACHE) < 1000:
        _COMPILED_HASH_CACHE[cache_key] = truncated_name

    return truncated_name

def run_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""

    print(f"æ–‡ä»¶åé•¿åº¦é™åˆ¶: {MAX_FILENAME_LENGTH} å­—ç¬¦")
    print("=" * 60)

    test_cases = [
        # çŸ­æ–‡ä»¶å
        {
            "input": "ç®€å•æ ‡é¢˜",
            "description": "çŸ­æ–‡ä»¶åä¸åº”æˆªæ–­"
        },

        # è¶…é•¿æ–‡ä»¶åï¼ˆå®é™…æ¡ˆä¾‹ï¼‰
        {
            "input": "ã€ç½‘ç«™è‡ªèã€‘æŠ•èµ„ç­–ç•¥æ¨¡æ‹Ÿå™¨---é€šè¿‡ç›´è§‚å¯è§†åŒ–ç•Œé¢å’Œè¯¦ç»†æ•°æ®åˆ†æï¼Œè®©ç”¨æˆ·æ·±å…¥äº†è§£å„ç§æŠ•èµ„ç­–ç•¥ä¼˜åŠ£ï¼Œä»è€Œåšå‡ºæ›´æ˜æ™ºæŠ•èµ„å†³ç­–-Â·-issue-#5288-Â·-ruanyf-weekly",
            "description": "è¶…é•¿æ–‡ä»¶åæµ‹è¯•"
        },

        # åŒ…å«ç‰¹æ®Šå­—ç¬¦
        {
            "input": "åŒ…å«/ç‰¹æ®Š\\å­—ç¬¦:*çš„æ–‡ä»¶?æ ‡é¢˜",
            "description": "ç‰¹æ®Šå­—ç¬¦æ¸…ç†æµ‹è¯•"
        },

        # è‹±æ–‡æ ‡é¢˜
        {
            "input": "A Very Long English Title with Many Words and Special Characters that Should Be Truncated Properly",
            "description": "è‹±æ–‡é•¿æ ‡é¢˜æµ‹è¯•"
        }
    ]

    all_passed = True

    for i, test_case in enumerate(test_cases, 1):
        print(f"\næµ‹è¯• {i}: {test_case['description']}")
        print(f"è¾“å…¥: {test_case['input'][:60]}{'...' if len(test_case['input']) > 60 else ''}")

        result = slugify(test_case['input'])
        print(f"è¾“å‡º: {result}")
        print(f"é•¿åº¦: {len(result)} å­—ç¬¦")

        # éªŒè¯é•¿åº¦é™åˆ¶
        if len(result) <= MAX_FILENAME_LENGTH:
            print("âœ“ é•¿åº¦æ£€æŸ¥é€šè¿‡")
        else:
            print(f"âœ— é•¿åº¦æ£€æŸ¥å¤±è´¥: {len(result)} > {MAX_FILENAME_LENGTH}")
            all_passed = False

        # éªŒè¯ä¸åŒ…å«éæ³•å­—ç¬¦
        illegal_chars = '/\\:*?"<>|'
        has_illegal = any(char in result for char in illegal_chars)
        if not has_illegal:
            print("âœ“ éæ³•å­—ç¬¦æ£€æŸ¥é€šè¿‡")
        else:
            print(f"âœ— éæ³•å­—ç¬¦æ£€æŸ¥å¤±è´¥: åŒ…å«éæ³•å­—ç¬¦")
            all_passed = False

        # éªŒè¯å”¯ä¸€æ€§å“ˆå¸Œå­˜åœ¨ï¼ˆå¯¹äºè¢«æˆªæ–­çš„æ–‡ä»¶ï¼‰
        if len(test_case['input']) > MAX_FILENAME_LENGTH:
            if '_' in result and result.split('_')[-1].isalnum():
                print("âœ“ å“ˆå¸Œåç¼€æ£€æŸ¥é€šè¿‡")
            else:
                print("âœ— å“ˆå¸Œåç¼€æ£€æŸ¥å¤±è´¥: ç¼ºå°‘å“ˆå¸Œåç¼€")
                all_passed = False

    print("\n" + "=" * 60)
    print("å”¯ä¸€æ€§æµ‹è¯•:")
    print("-" * 30)

    # æµ‹è¯•å”¯ä¸€æ€§
    base_title = "è¿™æ˜¯ä¸€ä¸ªå¾ˆé•¿å¾ˆé•¿çš„æ ‡é¢˜ç”¨æ¥æµ‹è¯•å“ˆå¸Œå”¯ä¸€æ€§"
    titles = [base_title + "ç‰ˆæœ¬" + str(i) for i in range(1, 5)]

    results = [slugify(title) for title in titles]
    unique_results = set(results)

    print(f"è¾“å…¥æ ‡é¢˜æ•°: {len(titles)}")
    print(f"ç”Ÿæˆç»“æœæ•°: {len(unique_results)}")

    if len(results) == len(unique_results):
        print("âœ“ å”¯ä¸€æ€§æ£€æŸ¥é€šè¿‡: æ‰€æœ‰ç»“æœéƒ½ä¸åŒ")
        uniqueness_passed = True
    else:
        print("âœ— å”¯ä¸€æ€§æ£€æŸ¥å¤±è´¥: å­˜åœ¨é‡å¤ç»“æœ")
        uniqueness_passed = False

    print("\n" + "=" * 60)
    print("æµ‹è¯•æ€»ç»“:")
    print(f"åŸºæœ¬åŠŸèƒ½: {'âœ“ é€šè¿‡' if all_passed else 'âœ— å¤±è´¥'}")
    print(f"å”¯ä¸€æ€§: {'âœ“ é€šè¿‡' if uniqueness_passed else 'âœ— å¤±è´¥'}")

    overall_passed = all_passed and uniqueness_passed

    if overall_passed:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! slugify å‡½æ•°å·¥ä½œæ­£å¸¸ã€‚")
    else:
        print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ç°ã€‚")

    return overall_passed

def test_performance():
    """æµ‹è¯•æ€§èƒ½ä¼˜åŒ–æ•ˆæœ"""
    import time

    print("\næ€§èƒ½æµ‹è¯•:")
    print("-" * 30)

    # æµ‹è¯•æ•°æ®
    test_texts = [
        "è¿™æ˜¯ä¸€ä¸ªå¾ˆé•¿çš„æ ‡é¢˜ç”¨æ¥æµ‹è¯•æ€§èƒ½" * 2,
        "ã€ç½‘ç«™è‡ªèã€‘æŠ•èµ„ç­–ç•¥æ¨¡æ‹Ÿå™¨---é€šè¿‡ç›´è§‚å¯è§†åŒ–ç•Œé¢å’Œè¯¦ç»†æ•°æ®åˆ†æï¼Œè®©ç”¨æˆ·æ·±å…¥äº†è§£å„ç§æŠ•èµ„ç­–ç•¥ä¼˜åŠ£ï¼Œä»è€Œåšå‡ºæ›´æ˜æ™ºæŠ•èµ„å†³ç­–-Â·-issue-#5288-Â·-ruanyf-weekly",
        "A Very Long English Title with Many Words" * 3,
        "åŒ…å«/ç‰¹æ®Š\\å­—ç¬¦:*çš„æ–‡ä»¶?æ ‡é¢˜" * 2
    ]

    # æ¸…ç©ºç¼“å­˜
    global _COMPILED_HASH_CACHE
    _COMPILED_HASH_CACHE.clear()

    # ç¬¬ä¸€æ¬¡è¿è¡Œï¼ˆæ— ç¼“å­˜ï¼‰
    start_time = time.time()
    for _ in range(100):
        for text in test_texts:
            slugify(text)
    first_run_time = time.time() - start_time

    # ç¬¬äºŒæ¬¡è¿è¡Œï¼ˆæœ‰ç¼“å­˜ï¼‰
    start_time = time.time()
    for _ in range(100):
        for text in test_texts:
            slugify(text)
    second_run_time = time.time() - start_time

    print(f"ç¬¬ä¸€æ¬¡è¿è¡Œï¼ˆæ— ç¼“å­˜ï¼‰: {first_run_time:.4f}ç§’")
    print(f"ç¬¬äºŒæ¬¡è¿è¡Œï¼ˆæœ‰ç¼“å­˜ï¼‰: {second_run_time:.4f}ç§’")

    if second_run_time < first_run_time:
        improvement = ((first_run_time - second_run_time) / first_run_time) * 100
        print(f"ç¼“å­˜ä¼˜åŒ–æå‡: {improvement:.1f}%")
        print("âœ“ æ€§èƒ½ä¼˜åŒ–æœ‰æ•ˆ")
    else:
        print("âš  ç¼“å­˜æ•ˆæœä¸æ˜æ˜¾ï¼ˆå¯èƒ½å› æ•°æ®é›†è¾ƒå°ï¼‰")

def run_comprehensive_tests():
    """è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶"""
    print("å¼€å§‹å…¨é¢æµ‹è¯•...")

    # åŸºæœ¬åŠŸèƒ½æµ‹è¯•
    basic_passed = run_tests()

    # æ€§èƒ½æµ‹è¯•
    test_performance()

    print("\n" + "=" * 60)
    print("æµ‹è¯•æ€»ç»“:")
    print(f"åŸºæœ¬åŠŸèƒ½: {'âœ“ é€šè¿‡' if basic_passed else 'âœ— å¤±è´¥'}")

    return basic_passed

if __name__ == "__main__":
    run_comprehensive_tests()